import pickle
import os
import numpy as np
from scipy import signal
from scipy.signal import firwin

def save_dict_and_description(dict_to_save, output_file_name, output_dir, description):
    # Save the dictionary to a pickle file
    with open(os.path.join(output_dir, f'{output_file_name}.pkl'), 'wb') as f:
        pickle.dump(dict_to_save, f)

    # Create the output text file path
    output_text_file_path = os.path.join(output_dir, f'{output_file_name}_description.txt')

    # Initialize the list to store the lines of the text file
    lines = []

    # Add the description to the lines
    lines.append(description)
    lines.append("\n\nKeys and shapes of arrays:\n")

    # Function to recursively get keys and shapes
    def get_keys_and_shapes(d, parent_key=''):
        for k, v in d.items():
            new_key = f"{parent_key}.{k}" if parent_key else k
            if isinstance(v, dict):
                if len(v) > 50:
                    first_value = next(iter(v.values()))
                    if isinstance(first_value, np.ndarray):
                        shape = list(first_value.shape)
                        shape[0] = 'N'
                        lines.append(f"{new_key}: {tuple(shape)}\n")
                    else:
                        lines.append(f"{new_key}: This is actually also a dictionary. However, there are too many keys to detail, each value is type: {type(first_value).__name__}\n")
                else:
                    get_keys_and_shapes(v, new_key)
            elif isinstance(v, np.ndarray):
                lines.append(f"{new_key}: {v.shape}\n")
            elif isinstance(v, tuple):
                tuple_shapes = [type(item).__name__ if not isinstance(item, np.ndarray) else item.shape for item in v]
                lines.append(f"{new_key}: tuple with element shapes {tuple_shapes}\n")
            else:
                lines.append(f"{new_key}: Not an array\n")

    # Get the keys and shapes
    get_keys_and_shapes(dict_to_save)

    # Write the lines to the output text file
    with open(output_text_file_path, 'w') as f:
        f.writelines(lines)


def peak_idx_correction(signal, peak_indices, num_neighbors=5):
    """
    This is written for BVDS dataset. Since David's algorithm's AO/AC timing output is generated by Kalman filter
    the timings were not spot on, but very close to the correct peak nearby. This function takes the signal, takes
    the wrong peak indices (wrong but very close to original peak), finds the nearest peak and updates it accordingly.
    Call it when you need to find nearest peaks.
    :param signal: Np array, 1 dimensional
    :param peak_indices: Np integer array consisting of wrong peak indices that are very close to correct peak indices
    :param num_neighbors: How many nearby samples you want to take a loot at to find the correct peak
    :return: Corrected peak indices
    """
    updated_peak_indices = []
    for peak_index in peak_indices:
        if peak_index < len(signal):
            peak_index = int(peak_index)
            max_value = signal[peak_index]
            max_index = peak_index
            # Check 5 points before and after the peak index
            for i in range(max(0, peak_index - num_neighbors), min(len(signal), peak_index + num_neighbors + 1)):
                if signal[i] > max_value:
                    max_value = signal[i]
                    max_index = i
            updated_peak_indices.append(max_index)
    return np.reshape(np.array(updated_peak_indices), (-1, 1))


# David's filter - original was in Matlab
def create_kaiser_BPF_for_signals(Fs, lower_cutoff, higher_cutoff, order, filter_type, scale, kaiser_beta):
    """
    Creates a kaiser BPF filter and returns it
    :param Fs: sampling rate
    :param lower_cutoff:
    :param higher_cutoff:
    :param order: order of the filter
    :param filter_type: True, False, ‘bandpass’, ‘lowpass’, ‘highpass’, ‘bandstop’
    :param scale: Set to True to scale the coefficients so that the frequency response is exactly unity at a certain frequency
    :param kaiser_beta:
    :return:
    """
    filter = firwin(order + 1, [lower_cutoff / (Fs / 2), higher_cutoff / (Fs / 2)],
           width=None, window=('kaiser', kaiser_beta), pass_zero=filter_type, scale=scale)
    return filter

def downsample_signal(x, downsampling_fac):
    """
    :param x: Numpy array shaped (N, )
    :param downsampling_fac: If you specify this as K, output will be K times less sampled
    :return:
    """
    out = signal.decimate(x, downsampling_fac)
    return out